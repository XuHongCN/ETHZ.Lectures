{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn  # for building up neural network\n",
    "from torch.utils.data import Dataset, DataLoader  # for loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate some data ##\n",
    "To demonstrate the capability of neural networks, we generate a classification dataset that is not easily linearly separable. So we use a common example -- spiral dataset. Data generation code comes from standford [cs231n](http://cs231n.github.io/neural-networks-case-study/) course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100 # number of points per class\n",
    "D = 2 # dimensionality\n",
    "K = 3 # number of classes\n",
    "X_data = np.zeros((N*K,D), dtype='float32') # data matrix (each row = single example)\n",
    "y_data = np.zeros(N*K, dtype='uint8') # class labels\n",
    "for j in range(K):\n",
    "  ix = range(N*j,N*(j+1))\n",
    "  r = np.linspace(0.0,1,N) # radius\n",
    "  t = np.linspace(j*4,(j+1)*4,N) + np.random.randn(N)*0.2 # theta\n",
    "  X_data[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
    "  y_data[ix] = j\n",
    "# visualize the data:\n",
    "plt.scatter(X_data[:, 0], X_data[:, 1], c=y_data, s=40, cmap=plt.cm.Spectral)\n",
    "plt.show()\n",
    "print('X_data shape: {}, y_data shape: {}'.format(X_data.shape, y_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building up a classifier using ANN ##\n",
    "We use `torch.nn.Modules` to build up the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNClassifier(nn.Module):\n",
    "    \"\"\" Simple classifier consisting of fully-connected layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, n_classes, n_hidden_neurons):\n",
    "        super(ANNClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(dim, n_hidden_neurons)\n",
    "        self.fc2 = nn.Linear(n_hidden_neurons, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the generated data ##\n",
    "PyTorch provides a data loading API in `torch.utils.data` module. PyTorch also provides various data pre-processing algorithms on images in `torchvision` module. A good (official) tutorial on using these APIs can be found [here](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html). Although our data in this tutorial do not have complicated structures, we still use `Dataset` and `DataLoader` from `torch.utils.data` from PyTorch for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpiralDataset(Dataset):\n",
    "    \"\"\" Spiral Dataset to load spiral data points.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx, transform=True):\n",
    "        sample = {'x': self.X[idx, :], 'y': self.y[idx]}  # We assume X has shape (N, dim), y has shape (N,)\n",
    "        # this is the canonical way of performing data preprocessing\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "    \n",
    "class ToTensor(object):\n",
    "    \"\"\" Converts numpy arrays in sample to Tensors\n",
    "    \"\"\"\n",
    "    def __call__(self, sample):\n",
    "        x, y = sample['x'], sample['y']\n",
    "        return {'x': torch.from_numpy(x), 'y': torch.LongTensor([y])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could have used `for` loop to load `SpiralDataset` simply by indexing it. For example:\n",
    "```python\n",
    "spiral_dataset = SpiralDataset(X, y)\n",
    "for i in range(len(spiral_dataset)):\n",
    "    sample = spiral_dataset[i]\n",
    "    x, y = sample['x'], sample['y']\n",
    "```\n",
    "But in this way, we lose a lot of features:\n",
    "- Batching the data\n",
    "- Shuffling the data\n",
    "\n",
    "`torch.utils.data.DataLoader` is an iterator which provides all these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first create a dataset\n",
    "spiral_dataset = SpiralDataset(X_data, y_data, transform=ToTensor())  # note that X and y are generated in the first section\n",
    "# then use Dataloader to wrap up the dataset \n",
    "spiral_dataloader = DataLoader(spiral_dataset, batch_size=32, shuffle=True)  \n",
    "# now we can use for loop to iterate over spiral_dataloader\n",
    "for i, sample in enumerate(spiral_dataloader):\n",
    "    if i == 3:\n",
    "        print(sample['x'].size(), sample['y'].size())\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the neural network ##\n",
    "We use `torch.optim.SGD`, i.e. stochastic gradient descent to optimize the weights of our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "n_epochs = 120\n",
    "batch_size = 32\n",
    "lr = 0.05\n",
    "n_hidden_neurons = 100\n",
    "\n",
    "# define the network\n",
    "ann = ANNClassifier(dim=D, n_classes=K, n_hidden_neurons=n_hidden_neurons)\n",
    "# define the loss function\n",
    "loss_fcn = nn.CrossEntropyLoss()\n",
    "# define the optimizer\n",
    "optimizer = torch.optim.Adam(ann.parameters(), lr=lr)\n",
    "# define the dataset\n",
    "spiral_dataset = SpiralDataset(X_data, y_data, transform=ToTensor())\n",
    "# define the data loader\n",
    "spiral_dataloader = DataLoader(spiral_dataset, batch_size=batch_size, shuffle=True, num_workers=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    n_correct_examples = 0\n",
    "    for i, sample in enumerate(spiral_dataloader):\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        x, y = sample['x'], sample['y'].squeeze()\n",
    "        y_score = ann(x)\n",
    "        loss = loss_fcn(y_score, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # compute training accuracy\n",
    "        y_pred = torch.argmax(nn.functional.softmax(y_score, dim=1), dim=1)\n",
    "        n_correct_examples += torch.sum(y_pred==y).item()\n",
    "    if epoch % 5 == 0:\n",
    "        print('epoch {}, training accuracy = {:.3f}'.format(epoch, n_correct_examples/len(spiral_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
